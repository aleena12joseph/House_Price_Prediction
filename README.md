# ğŸ¡ Boston Housing Price Prediction â€“ Algorithm Comparison

A machine learning project that predicts **house prices** using multiple algorithms on the **Boston Housing dataset**.  
The project compares **Linear Regression, Random Forest, and XGBoost** to evaluate which algorithm performs best.

---

## ğŸ“Œ Problem Statement

To build a predictive system that estimates the **median value of homes (MEDV)** in Boston based on socio-economic and structural features.  
The goal is to compare multiple regression algorithms and identify the most effective one.

---

## ğŸ’¡ Proposed Solution

* Use the **Boston Housing dataset** containing 13 independent features and the target variable `MEDV`.  
* Preprocess the data and split into training/testing sets.  
* Train 3 models:
  - **Linear Regression** â€“ baseline model
  - **Random Forest Regressor** â€“ ensemble model
  - **XGBoost Regressor** â€“ gradient boosting model  
* Evaluate using **RMSE** and **RÂ² score**.  
* Compare performance and visualize results.  

---

## ğŸš° Technologies Used

* Python  
* pandas, numpy â€“ data processing  
* seaborn, matplotlib â€“ visualization  
* scikit-learn â€“ regression models & metrics  
* xgboost â€“ gradient boosting  

---

## ğŸ“ Dataset

The dataset (`boston.csv`) includes features like:  

- **CRIM**: Crime rate per capita  
- **ZN**: Proportion of residential land zoned  
- **RM**: Average number of rooms per dwelling  
- **LSTAT**: % lower status of population  
- **PTRATIO**: Pupil-teacher ratio  
- **MEDV**: Median value of owner-occupied homes (target)  

---

## ğŸ§  Machine Learning Models

### ğŸ”¹ Linear Regression
* Simple, interpretable baseline model.  
* Assumes linear relationship between features and price.  

### ğŸ”¹ Random Forest Regressor
* Ensemble of decision trees.  
* Handles non-linear patterns well.  
* Reduces variance compared to single decision tree.  

### ğŸ”¹ XGBoost Regressor
* Gradient boosting algorithm.  
* Highly accurate and efficient for tabular data.  
* Provides feature importance.  

---

## ğŸ“Š Model Evaluation

| Algorithm             | RMSE   | RÂ² Score |
|---------------------- | ------ | -------- |
| Linear Regression     | 4.9   | 0.67     |
| Random Forest         | 2.8   | 0.89     |
| XGBoost Regressor     | 2.55   | 0.91     |

âœ… **XGBoost performed the best**, explaining ~91% of the variance in house prices.  
Linear Regression provided a good baseline, while Random Forest also achieved strong results.  

---

## ğŸ“ˆ Visualization

1. **Prediction vs Actual** â€“ Scatter plots for each model to show accuracy.  
2. **Feature Importance** â€“ From Random Forest & XGBoost, showing key features like `RM`, `LSTAT`, `PTRATIO`.  
3. **Comparison Bar Chart** â€“ RMSE/RÂ² comparison across algorithms.  

---

## ğŸš€ Future Scope

* Apply hyperparameter tuning (GridSearchCV / RandomizedSearchCV).  
* Add more features (e.g., location, economic indicators).  
* Deploy as a **Flask/Django web app** for real-time predictions.  
* Try deep learning models (Neural Networks).  

---

## âœ… Summary

This project compares **three machine learning algorithms** for predicting Boston housing prices.  
While Linear Regression serves as a baseline, **XGBoost provides the most accurate predictions**, proving the effectiveness of gradient boosting for regression tasks.  

---
ğŸ“œ License: MIT

